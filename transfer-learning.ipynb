{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01408707-15a9-457c-9b6c-ba49dbfeb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93888455-f336-4672-9b2d-6c3b247cba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pytorchcv import train, plot_results, display_dataset, train_long, check_image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2e570-0a47-4a8c-8fcd-5428d8a3b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/kagglecatsanddogs_5340.zip'):\n",
    "    !wget -P data -q https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f7a72-79a6-4ef3-a51b-cd5bc4b138d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "if not os.path.exists('data/PetImages'):\n",
    "    with zipfile.ZipFile('data/kagglecatsanddogs_5340.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259546a5-5715-4a69-90a1-245ab891f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image_dir('data/PetImages/Cat/*.jpg')\n",
    "check_image_dir('data/PetImages/Dog/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba339e2a-0e9d-496b-8b8b-645c8a5d1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(), \n",
    "        std_normalize])\n",
    "dataset = torchvision.datasets.ImageFolder('data/PetImages',transform=trans)\n",
    "trainset, testset = torch.utils.data.random_split(dataset,[20000,len(dataset)-20000])\n",
    "\n",
    "display_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303d49-f44b-4da6-92f8-fd56d588f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model weights in the sandbox environment\n",
    "!mkdir -p models\n",
    "!wget -P models https://github.com/MicrosoftDocs/pytorchfundamentals/raw/main/computer-vision-pytorch/vgg16-397923af.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc77ab5-5475-4835-827d-d94e888c99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'models/vgg16-397923af.pth'\n",
    "\n",
    "vgg = torchvision.models.vgg16()\n",
    "vgg.load_state_dict(torch.load(file_path))\n",
    "vgg.eval()\n",
    "\n",
    "sample_image = dataset[0][0].unsqueeze(0)\n",
    "res = vgg(sample_image)\n",
    "print(res[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff9b50-3395-4791-8208-1ae866ebf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "class_map = json.loads(requests.get(\"https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/imagenet_class_index.json\").text)\n",
    "class_map = { int(k) : v for k,v in class_map.items() }\n",
    "\n",
    "class_map[res[0].argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd5ad6-d50c-49d0-88d9-faf2b2c06e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vgg,input_size=(1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bc359-d5da-4f27-b094-b1cc9324d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Doing computations on device = {}'.format(device))\n",
    "\n",
    "vgg.to(device)\n",
    "sample_image = sample_image.to(device)\n",
    "\n",
    "vgg(sample_image).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0540c76-e87b-4e34-a830-550977febf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vgg.features(sample_image).cpu()\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.imshow(res.detach().view(-1,512))\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde8a82-c76b-4b31-9941-9379857f0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "dl = torch.utils.data.DataLoader(dataset,batch_size=bs,shuffle=True)\n",
    "num = bs*100\n",
    "feature_tensor = torch.zeros(num,512*7*7).to(device)\n",
    "label_tensor = torch.zeros(num).to(device)\n",
    "i = 0\n",
    "for x,l in dl:\n",
    "    with torch.no_grad():\n",
    "        f = vgg.features(x.to(device))\n",
    "        feature_tensor[i:i+bs] = f.view(bs,-1)\n",
    "        label_tensor[i:i+bs] = l\n",
    "        i+=bs\n",
    "        print('.',end='')\n",
    "        if i>=num:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f194f4a-39d1-4808-b461-e6d806d5d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_dataset = torch.utils.data.TensorDataset(feature_tensor,label_tensor.to(torch.long))\n",
    "train_ds, test_ds = torch.utils.data.random_split(vgg_dataset,[700,100])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds,batch_size=32)\n",
    "\n",
    "net = torch.nn.Sequential(torch.nn.Linear(512*7*7,2),torch.nn.LogSoftmax()).to(device)\n",
    "\n",
    "history = train(net,train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0422cd-558f-4031-bb07-379a91516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc9bb7-63ec-42da-918f-a9e286177243",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier = torch.nn.Linear(25088,2).to(device)\n",
    "\n",
    "for x in vgg.features.parameters():\n",
    "    x.requires_grad = False\n",
    "\n",
    "summary(vgg,(1, 3,244,244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319a804-14a4-40ec-aabe-ca38f0012f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = torch.utils.data.random_split(dataset,[20000,len(dataset)-20000])\n",
    "train_loader = torch.utils.data.DataLoader(trainset,batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=16)\n",
    "\n",
    "train_long(vgg,train_loader,test_loader,loss_fn=torch.nn.CrossEntropyLoss(),epochs=1,print_freq=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569226bb-ad75-4660-962b-c6a2d0bc13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg,'data/cats_dogs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d29f29-73be-4c11-98da-ea198564c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = torch.load('data/cats_dogs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff03a1-18d0-4697-8b0c-5afb74442a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in vgg.features.parameters():\n",
    "    x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae04595-ca65-4e02-bca7-fdc9c5f450c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_long(vgg,train_loader,test_loader,loss_fn=torch.nn.CrossEntropyLoss(),epochs=1,print_freq=90,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079c6d9-bc87-43e0-8646-2df26464a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18()\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41fe57-95f4-4f91-b2dc-754242e753f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
