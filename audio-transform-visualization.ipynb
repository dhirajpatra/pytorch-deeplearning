{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ee0ba-d08d-4039-92b8-f96def79c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd5894-8ff3-4aa0-9ac5-4d1df67321e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(path: str, label:str):\n",
    "\n",
    "    dataset = []\n",
    "    walker = sorted(str(p) for p in Path(path).glob(f'*.wav'))\n",
    "\n",
    "    for i, file_path in enumerate(walker):\n",
    "        path, filename = os.path.split(file_path)\n",
    "        speaker, _ = os.path.splitext(filename)\n",
    "        speaker_id, utterance_number = speaker.split(\"_nohash_\")\n",
    "        utterance_number = int(utterance_number)\n",
    "    \n",
    "        # Load audio\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        dataset.append([waveform, sample_rate, label, speaker_id, utterance_number])\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabffb7-d527-4a4a-8d97-e6791eb9f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_speechcommands_yes = load_audio_files('./data/SpeechCommands/speech_commands_v0.02/yes', 'yes')\n",
    "trainset_speechcommands_no = load_audio_files('./data/SpeechCommands/speech_commands_v0.02/no', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38c02c-636d-4830-a5bf-9263b97747ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of yes dataset: {len(trainset_speechcommands_yes)}')\n",
    "print(f'Length of no dataset: {len(trainset_speechcommands_no)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb791fb5-cb37-4941-a758-2b3cd2fda970",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_yes = torch.utils.data.DataLoader(trainset_speechcommands_yes, batch_size=1,\n",
    "                                            shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05dceb-ea2a-49e4-9b2d-7d21c5660078",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_no = torch.utils.data.DataLoader(trainset_speechcommands_no, batch_size=1,\n",
    "                                            shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a2438-789c-43c8-b5f2-a237aec24879",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_waveform = trainset_speechcommands_yes[0][0]\n",
    "yes_sample_rate = trainset_speechcommands_yes[0][1]\n",
    "print(f'Yes Waveform: {yes_waveform}')\n",
    "print(f'Yes Sample Rate: {yes_sample_rate}')\n",
    "print(f'Yes Label: {trainset_speechcommands_yes[0][2]}')\n",
    "print(f'Yes ID: {trainset_speechcommands_yes[0][3]} \\n')\n",
    "\n",
    "no_waveform = trainset_speechcommands_no[0][0]\n",
    "no_sample_rate = trainset_speechcommands_no[0][1]\n",
    "print(f'No Waveform: {no_waveform}')\n",
    "print(f'No Sample Rate: {no_sample_rate}')\n",
    "print(f'No Label: {trainset_speechcommands_no[0][2]}')\n",
    "print(f'No ID: {trainset_speechcommands_no[0][3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f30dbf-c623-48de-ae78-f031b7479f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_waveform(waveform, sample_rate, label):\n",
    "    print(\"Waveform: {}\\nSample rate: {}\\nLabels: {} \\n\".format(waveform, sample_rate, label))\n",
    "    new_sample_rate = sample_rate/10\n",
    "   \n",
    "    # Resample applies to a single channel, we resample first channel here\n",
    "    channel = 0\n",
    "    waveform_transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform[channel,:].view(1,-1))\n",
    "\n",
    "    print(\"Shape of transformed waveform: {}\\nSample rate: {}\".format(waveform_transformed.size(), new_sample_rate))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(waveform_transformed[0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54c40f-2065-479a-93ff-93ba92172ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform(yes_waveform, yes_sample_rate, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f181e0-9651-4482-87a8-8058737afcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform(no_waveform, no_sample_rate, 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56f25b-4074-46ff-8af3-7d75862f0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectrogram(waveform_classA, waveform_classB):\n",
    "    yes_spectrogram = torchaudio.transforms.Spectrogram()(waveform_classA)\n",
    "    print(\"\\nShape of yes spectrogram: {}\".format(yes_spectrogram.size()))\n",
    "    \n",
    "    no_spectrogram = torchaudio.transforms.Spectrogram()(waveform_classB)\n",
    "    print(\"Shape of no spectrogram: {}\".format(no_spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Features of {}\".format('no'))\n",
    "    plt.imshow(yes_spectrogram.log2()[0,:,:].numpy(), cmap='viridis')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Features of {}\".format('yes'))\n",
    "    plt.imshow(no_spectrogram.log2()[0,:,:].numpy(), cmap='viridis')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61b7a8-b064-4790-81c7-f48f4f76a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectrogram(yes_waveform, no_waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77830131-ee58-43f5-aeba-c7a599ff20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_melspectrogram(waveform,sample_rate):\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate)(waveform)\n",
    "    print(\"Shape of spectrogram: {}\".format(mel_spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(mel_spectrogram.log2()[0,:,:].numpy(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802fb14-3d6c-4a9d-89a0-3dca4b5b2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_melspectrogram(yes_waveform, yes_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa264b8-98da-4d0d-ac93-d34a2c2da880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mfcc(waveform,sample_rate):\n",
    "    mfcc_spectrogram = torchaudio.transforms.MFCC(sample_rate= sample_rate)(waveform)\n",
    "    print(\"Shape of spectrogram: {}\".format(mfcc_spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    fig1 = plt.gcf()\n",
    "    plt.imshow(mfcc_spectrogram.log2()[0,:,:].numpy(), cmap='viridis')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(mfcc_spectrogram.log2()[0,:,:].numpy())\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b75916-d1e6-430e-a586-1d3585e2a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mfcc(no_waveform,  no_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8a83a-363e-4dfb-8596-5128f4712275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_images(trainloader, label_dir):\n",
    "    #make directory\n",
    "    directory = f'./data/spectrograms/{label_dir}/'\n",
    "    if(os.path.isdir(directory)):\n",
    "        print(\"Data exists for\", label_dir)\n",
    "    else:\n",
    "        os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "\n",
    "            waveform = data[0]\n",
    "            sample_rate = data[1][0]\n",
    "            label = data[2]\n",
    "            ID = data[3]\n",
    "\n",
    "            # create transformed waveforms\n",
    "            spectrogram_tensor = torchaudio.transforms.Spectrogram()(waveform)     \n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.imsave(f'./data/spectrograms/{label_dir}/spec_img{i}.png', spectrogram_tensor[0].log2()[0,:,:].numpy(), cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41cd9c-44be-4dea-bbbc-c7fa3d8ba844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mfcc_images(trainloader, label_dir):\n",
    "    #make directory\n",
    "    os.makedirs(f'./data/mfcc_spectrograms/{label_dir}/', mode=0o777, exist_ok=True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        waveform = data[0]\n",
    "        sample_rate = data[1][0]\n",
    "        label = data[2]\n",
    "        ID = data[3]\n",
    "        \n",
    "        mfcc_spectrogram = torchaudio.transforms.MFCC(sample_rate= sample_rate)(waveform)\n",
    "\n",
    "        plt.figure()\n",
    "        fig1 = plt.gcf()\n",
    "        plt.imshow(mfcc_spectrogram[0].log2()[0,:,:].numpy(), cmap='viridis')\n",
    "        plt.draw()\n",
    "        fig1.savefig(f'./data/mfcc_spectrograms/{label_dir}/spec_img{i}.png', dpi=100)\n",
    " \n",
    "        #spectorgram_train.append([spectrogram_tensor, label, sample_rate, ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ec672-9b9f-4614-9629-f4a6d06d3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_spectrogram_images(trainloader_yes, 'yes')\n",
    "create_spectrogram_images(trainloader_no, 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f80d2-a1bc-425b-8235-0c8da5bbf4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
