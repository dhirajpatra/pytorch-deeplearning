{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4da58b6-de03-459c-b1a8-e78e8c173ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501d67d7-f7f5-4830-be3d-6f3d5e4a5c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae443719-f256-42b3-b050-17063f4a5c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafd5b1c-c682-4e47-ad63-db3d95eb8337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6fe5fa-daf7-4554-afa7-7c84fbf958d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X) \n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86b5b8b-2d5d-4b89-adf8-ec762f7355ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[-0.0189, -0.0318,  0.0277,  ..., -0.0250, -0.0062, -0.0323],\n",
      "        [ 0.0164, -0.0044, -0.0080,  ..., -0.0325, -0.0084, -0.0216],\n",
      "        [ 0.0346, -0.0332,  0.0145,  ...,  0.0124,  0.0180,  0.0162],\n",
      "        ...,\n",
      "        [-0.0072,  0.0007, -0.0326,  ..., -0.0299, -0.0324, -0.0069],\n",
      "        [-0.0291,  0.0062,  0.0118,  ...,  0.0320,  0.0107,  0.0164],\n",
      "        [-0.0284, -0.0144,  0.0039,  ...,  0.0160,  0.0229,  0.0081]],\n",
      "       requires_grad=True) \n",
      "\n",
      "First Linear biases: Parameter containing:\n",
      "tensor([-1.8573e-02, -3.2777e-02, -2.9158e-02,  9.0397e-03, -2.2169e-02,\n",
      "        -1.2472e-02, -2.2139e-02, -1.6919e-02, -1.2197e-02,  5.2545e-03,\n",
      "         1.5073e-02, -2.7256e-02,  9.4085e-03, -9.0370e-03, -1.9046e-02,\n",
      "        -1.6046e-02, -1.9185e-02, -3.8207e-03,  2.9930e-02, -2.5440e-03,\n",
      "         2.1869e-02, -5.7410e-03,  1.3322e-02, -4.3603e-03,  2.3443e-02,\n",
      "         4.2585e-03, -2.2333e-03,  2.5732e-02,  2.4338e-02,  1.2031e-02,\n",
      "         3.5076e-02,  1.4905e-02, -3.1650e-02, -1.5538e-02,  1.2607e-02,\n",
      "         1.3308e-03,  3.4330e-02,  3.1490e-02, -3.2398e-02,  2.4888e-02,\n",
      "        -2.3421e-03,  1.7107e-02, -5.2614e-03,  3.7074e-03,  3.1342e-02,\n",
      "         3.0571e-02, -1.0767e-02,  2.0443e-02,  8.3592e-03, -3.1098e-02,\n",
      "        -2.0481e-02,  4.7308e-04, -9.3615e-03, -4.5300e-03, -2.0131e-02,\n",
      "        -7.0185e-03,  1.9831e-02, -2.2285e-02,  2.8121e-03,  2.3380e-02,\n",
      "        -3.2953e-02, -4.0704e-03, -2.2955e-02, -1.5924e-02,  1.9574e-02,\n",
      "        -1.1600e-02, -2.3087e-02,  2.4817e-02,  2.3528e-02, -1.8194e-02,\n",
      "        -1.9120e-02,  3.2763e-02, -1.6004e-02,  9.5170e-03,  6.4547e-03,\n",
      "         3.4776e-02,  1.7883e-03, -2.3820e-02,  2.1478e-02, -1.0769e-02,\n",
      "        -3.2937e-02, -3.0701e-02, -5.5958e-03, -8.2131e-03,  8.7891e-03,\n",
      "         1.8236e-02, -6.4870e-04, -1.2286e-02, -2.4361e-02,  2.0388e-02,\n",
      "         1.5163e-02, -1.6015e-02,  2.9891e-02, -2.3844e-02, -3.2331e-02,\n",
      "        -6.1163e-04,  2.6001e-02, -9.4795e-03, -1.9741e-02, -5.8248e-03,\n",
      "         2.5022e-02,  9.3405e-03,  3.2676e-02, -1.2808e-03, -3.4151e-02,\n",
      "        -1.4093e-02,  2.7154e-02,  1.9577e-02, -3.4379e-02,  6.5106e-03,\n",
      "        -2.3965e-02, -6.2460e-03,  2.9190e-02,  8.1447e-03,  9.1093e-04,\n",
      "         7.5999e-03,  1.3585e-02, -2.9488e-02,  8.0507e-03, -5.5352e-03,\n",
      "        -1.2062e-02, -2.4768e-02,  2.1904e-02,  2.4579e-02, -3.3813e-02,\n",
      "        -1.7038e-02, -6.2959e-03, -6.1858e-04,  2.6218e-02,  3.2903e-02,\n",
      "         1.4344e-02,  1.6382e-02, -2.7803e-02,  8.6534e-03, -9.3644e-03,\n",
      "         2.3208e-02,  2.1640e-02,  1.1495e-02, -3.3601e-03, -9.7876e-03,\n",
      "        -1.8755e-02, -2.7501e-02,  1.1676e-02,  1.5605e-02, -1.0399e-03,\n",
      "         1.6560e-02, -3.4050e-02, -1.9859e-03, -2.2895e-02, -2.8431e-02,\n",
      "         2.5341e-02,  2.4968e-02, -1.6753e-02,  1.9851e-02, -2.2089e-02,\n",
      "         1.4609e-02,  2.5440e-03,  2.6679e-02,  2.6677e-02, -1.3132e-02,\n",
      "         2.9008e-02, -8.9693e-03,  2.8913e-02, -9.7850e-03,  1.3038e-02,\n",
      "        -2.4268e-02,  3.3816e-02, -1.2853e-03,  3.3050e-02,  2.5735e-02,\n",
      "        -4.5432e-03,  6.7831e-03,  2.1655e-02,  2.3709e-02,  3.1618e-02,\n",
      "         3.4528e-02,  2.1545e-02,  2.5188e-02,  2.2377e-02,  1.4332e-02,\n",
      "         2.1914e-02, -1.1674e-02,  1.1591e-02, -1.3577e-02,  2.8219e-02,\n",
      "         1.0966e-02,  1.1690e-02, -1.4185e-02, -5.7101e-03, -3.1688e-02,\n",
      "        -2.5665e-02, -9.6575e-03, -5.2221e-03,  1.1542e-02, -1.1367e-02,\n",
      "        -1.2922e-02, -3.5117e-02, -1.1037e-02, -1.1658e-02, -1.7615e-02,\n",
      "        -2.0493e-02,  2.9124e-02, -9.6828e-03, -3.1498e-02,  3.1351e-02,\n",
      "        -1.4420e-03, -6.0101e-03,  1.4033e-02,  1.4645e-02, -2.5621e-02,\n",
      "         2.2747e-02,  1.4596e-02,  1.8862e-02, -3.0035e-02, -2.0083e-02,\n",
      "         2.0949e-02,  1.4783e-02,  1.5669e-02, -2.6027e-02,  1.9270e-03,\n",
      "         1.7881e-02,  9.5567e-03, -1.2668e-02, -1.1598e-02, -1.1500e-02,\n",
      "         2.8925e-02, -1.6776e-02,  1.0378e-02, -2.8292e-02,  3.2743e-02,\n",
      "         2.3355e-02, -1.9738e-02, -2.3967e-02, -3.4666e-02, -2.7663e-02,\n",
      "        -1.3476e-02, -1.8219e-03, -2.6269e-02,  1.2188e-02,  7.9195e-03,\n",
      "         3.2468e-02, -1.0115e-02,  1.0966e-03,  7.9769e-03,  1.3148e-02,\n",
      "        -3.3291e-02, -1.2971e-02, -1.6751e-02, -2.2285e-02,  2.0050e-02,\n",
      "        -2.3976e-02, -2.7233e-02,  2.3233e-02,  6.0565e-03,  1.0499e-02,\n",
      "        -3.4466e-03,  2.1552e-02, -2.5797e-02,  4.5002e-03, -3.8759e-03,\n",
      "         1.9752e-02,  1.2270e-02, -1.9970e-04, -1.9548e-02,  6.6348e-03,\n",
      "         2.6102e-02,  1.5542e-03, -8.9311e-03,  2.6814e-02,  3.2868e-02,\n",
      "        -6.5937e-03,  2.9548e-02, -1.0877e-02, -5.4036e-03,  1.3343e-02,\n",
      "        -2.7891e-02,  2.7206e-02, -2.5997e-02,  1.2175e-03, -2.6488e-02,\n",
      "        -3.8159e-03, -2.0074e-02, -3.9909e-03,  3.6265e-03, -3.5091e-02,\n",
      "        -1.3486e-02,  2.5562e-02, -2.8550e-02, -1.3016e-02, -3.3142e-02,\n",
      "         2.6823e-02, -4.0890e-03, -2.9379e-02, -1.9916e-02, -2.8744e-02,\n",
      "        -6.5051e-03, -2.5786e-02,  2.3490e-02,  6.8260e-03, -3.1464e-02,\n",
      "        -1.9483e-02, -1.3790e-04, -2.5413e-02,  1.2661e-02, -8.2995e-03,\n",
      "        -3.4951e-02, -1.7873e-02,  5.7453e-03, -2.7528e-02, -2.1124e-02,\n",
      "         1.0555e-03,  2.7723e-02, -2.1855e-02,  1.4355e-02,  9.6608e-03,\n",
      "        -6.3242e-03,  2.4117e-02,  1.8106e-02, -2.3594e-02,  5.6927e-03,\n",
      "         2.0952e-02,  2.4270e-02,  2.6159e-02,  2.0759e-02, -1.4088e-02,\n",
      "        -8.7452e-03, -1.1460e-02,  1.3663e-02,  1.8356e-02,  2.3003e-02,\n",
      "         3.4170e-02,  1.3777e-02,  1.5607e-02, -3.0568e-03,  1.6533e-02,\n",
      "         7.4877e-03, -1.3766e-02,  3.1547e-02, -1.1687e-02, -8.4023e-03,\n",
      "         8.6920e-03, -2.7019e-02, -1.9832e-02, -2.4281e-02, -1.1627e-02,\n",
      "        -1.9125e-02,  1.2525e-02, -1.7879e-02, -3.5587e-02, -2.0888e-02,\n",
      "        -1.2156e-02, -1.6256e-02,  2.5347e-02, -2.4135e-02, -2.0499e-03,\n",
      "        -1.2267e-02, -1.9326e-02,  3.0164e-02,  1.4729e-02,  2.5311e-03,\n",
      "        -3.0256e-02,  3.1322e-02,  2.1273e-02,  3.1369e-02, -1.4538e-02,\n",
      "        -2.9774e-02,  2.5172e-02,  3.2316e-02,  1.3294e-02,  2.2634e-02,\n",
      "        -3.0212e-02,  9.0065e-03,  1.8074e-02,  1.1487e-02,  2.3641e-02,\n",
      "         3.6359e-03, -2.4080e-02, -2.7393e-02,  1.8521e-02, -3.4824e-02,\n",
      "        -3.5575e-02, -2.6972e-02, -2.4051e-02, -2.6802e-02,  2.5061e-02,\n",
      "        -2.9793e-02, -8.4790e-03, -1.2606e-03, -9.3639e-04,  3.3194e-02,\n",
      "         1.0454e-02,  1.9907e-02,  7.0953e-03,  1.9166e-02,  1.1295e-02,\n",
      "        -2.2259e-02,  1.9939e-02, -9.9671e-03,  2.2201e-02,  7.0083e-03,\n",
      "         8.4022e-03, -2.6579e-02,  3.2342e-02, -2.2081e-02,  3.2050e-02,\n",
      "         1.0996e-02,  2.6243e-02, -2.6428e-02, -3.0639e-02, -1.6222e-02,\n",
      "         1.7823e-02, -9.4149e-03, -2.7002e-02, -8.7913e-03, -5.1465e-03,\n",
      "         2.1269e-02, -1.6809e-02,  2.4152e-02,  7.3838e-03,  1.3283e-02,\n",
      "        -1.9842e-02, -3.7172e-03,  5.9402e-03, -1.8850e-02,  1.0338e-02,\n",
      "        -1.8752e-02, -2.2331e-02,  2.5659e-03, -1.7609e-03,  3.2851e-02,\n",
      "        -7.7968e-03, -8.1932e-03,  3.1579e-02, -4.2506e-03, -6.6122e-04,\n",
      "        -5.4607e-03, -1.7884e-02, -7.2374e-03, -1.9160e-02, -8.1680e-03,\n",
      "         5.6367e-03,  6.9082e-03,  8.3651e-03,  7.8685e-03, -8.1728e-03,\n",
      "        -2.1886e-02,  1.9614e-02, -3.4898e-02, -2.3178e-02, -2.6603e-02,\n",
      "         2.3024e-02,  3.2174e-03, -1.1830e-02, -2.8886e-02,  3.5032e-02,\n",
      "         1.4863e-02, -1.4470e-02, -2.5762e-02, -3.2145e-02,  2.1235e-02,\n",
      "         2.5388e-02, -2.4634e-02,  2.7033e-02,  2.3250e-02, -7.8422e-03,\n",
      "        -2.7649e-02, -1.2510e-03,  3.2059e-02,  1.8039e-02, -3.3960e-02,\n",
      "         1.9156e-02, -2.8997e-02,  1.6522e-02, -1.8410e-02,  2.8929e-02,\n",
      "         1.2605e-02,  2.0660e-02, -2.7659e-02,  1.2893e-02,  2.2837e-02,\n",
      "         6.9453e-03, -5.5770e-03, -6.9675e-03,  1.9526e-02,  1.6199e-02,\n",
      "         1.0774e-02, -2.3368e-02,  1.8981e-02, -2.7036e-04, -2.0269e-02,\n",
      "         5.1517e-05, -3.3563e-02,  2.4997e-02,  1.2885e-02,  1.3675e-02,\n",
      "         2.4372e-02, -1.3068e-02,  3.0499e-02,  2.6163e-02,  2.2980e-02,\n",
      "        -1.1520e-03,  3.5478e-02, -2.8925e-02,  3.3331e-02,  4.6489e-03,\n",
      "        -1.1824e-02,  3.3608e-02,  4.9920e-03, -1.7715e-03,  1.2185e-03,\n",
      "         3.5044e-02, -1.9631e-02], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "\n",
    "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a641fdb-c669-41f3-8bce-64ad05f03f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf073099-92ac-411c-b304-0d9a17eed590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc6d95b-0487-4914-9b24-3b269c06d559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962280b-58f7-43d2-835d-2346d46f5dfd",
   "metadata": {},
   "source": [
    "Linear output: x=weight∗input+bias.\n",
    "ReLU: f(x)={ \n",
    "0,\n",
    "x,\n",
    "​\n",
    "  \n",
    "if x<0\n",
    "if x≥0\n",
    "​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b6f2b7-f4b9-4f85-9b10-87fc5234d974",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.2587, -0.1937,  0.2900, -0.6965,  0.2124,  0.3768,  0.0071, -0.5268,\n",
      "          0.0644,  0.2925, -0.1899, -0.8877, -0.1587,  0.1885, -0.2092, -0.5640,\n",
      "          0.2925,  0.1036, -0.1579,  0.0745],\n",
      "        [ 0.0011, -0.3910,  0.2956, -0.4342,  0.0673, -0.0278,  0.0462, -0.5101,\n",
      "          0.1592,  0.0860, -0.0699, -0.6120,  0.0625,  0.3854, -0.1252, -0.8362,\n",
      "          0.6542, -0.2141,  0.0243, -0.0541],\n",
      "        [ 0.0076, -0.3612,  0.2718, -0.0806,  0.0559,  0.4110, -0.0677, -0.1668,\n",
      "         -0.1608,  0.1173,  0.1008, -0.4816,  0.3751,  0.1695, -0.1949, -0.7563,\n",
      "          0.8795, -0.2001, -0.3097,  0.0115]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.2900, 0.0000, 0.2124, 0.3768, 0.0071, 0.0000, 0.0644,\n",
      "         0.2925, 0.0000, 0.0000, 0.0000, 0.1885, 0.0000, 0.0000, 0.2925, 0.1036,\n",
      "         0.0000, 0.0745],\n",
      "        [0.0011, 0.0000, 0.2956, 0.0000, 0.0673, 0.0000, 0.0462, 0.0000, 0.1592,\n",
      "         0.0860, 0.0000, 0.0000, 0.0625, 0.3854, 0.0000, 0.0000, 0.6542, 0.0000,\n",
      "         0.0243, 0.0000],\n",
      "        [0.0076, 0.0000, 0.2718, 0.0000, 0.0559, 0.4110, 0.0000, 0.0000, 0.0000,\n",
      "         0.1173, 0.1008, 0.0000, 0.3751, 0.1695, 0.0000, 0.0000, 0.8795, 0.0000,\n",
      "         0.0000, 0.0115]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ff4e9f-2cbb-4631-b354-ff12b04104c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60e3dd4-ee62-4681-9dd4-d639010c820b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e6555f-04c8-417a-bca1-212580a57d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0189, -0.0318,  0.0277,  ..., -0.0250, -0.0062, -0.0323],\n",
      "        [ 0.0164, -0.0044, -0.0080,  ..., -0.0325, -0.0084, -0.0216]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0186, -0.0328], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0281, -0.0146,  0.0222,  ...,  0.0133, -0.0006, -0.0084],\n",
      "        [-0.0129,  0.0214,  0.0442,  ..., -0.0317,  0.0258, -0.0154]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0022, -0.0046], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0112,  0.0034, -0.0027,  ..., -0.0437, -0.0102, -0.0221],\n",
      "        [ 0.0389,  0.0372,  0.0302,  ...,  0.0437,  0.0002,  0.0302]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0310, -0.0023], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbbf7e6-693f-4f73-9086-8f4704a9788e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
