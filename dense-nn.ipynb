{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4cb676-9274-47e3-99fd-28ed172142f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/pytorchcv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73a533-d7d1-472c-86e4-e54387b90614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "from pytorchcv import load_mnist, plot_results\n",
    "load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ace84d-4a5f-4561-99cb-c9d1ed03b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Flatten(), \n",
    "        nn.Linear(784,10), # 784 inputs, 10 outputs\n",
    "        nn.LogSoftmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e5f14-9177-4bea-b12a-5cd5cee00524",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Digit to be predicted: ',data_train[0][1])\n",
    "torch.exp(net(data_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe90d8-f548-4e62-88d8-f6aa77b15500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_train,batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(data_test,batch_size=64) # we can use larger batch size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceaa369-7b16-4499-86e9-823e467c3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,dataloader,lr=0.01,optimizer=None,loss_fn = nn.NLLLoss()):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    net.train()\n",
    "    total_loss,acc,count = 0,0,0\n",
    "    for features,labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "    return total_loss.item()/count, acc.item()/count\n",
    "\n",
    "train_epoch(net,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5462723-1fe4-4036-84d2-d114d640c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, dataloader,loss_fn=nn.NLLLoss()):\n",
    "    net.eval()\n",
    "    count,acc,loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for features,labels in dataloader:\n",
    "            out = net(features)\n",
    "            loss += loss_fn(out,labels) \n",
    "            pred = torch.max(out,1)[1]\n",
    "            acc += (pred==labels).sum()\n",
    "            count += len(labels)\n",
    "    return loss.item()/count, acc.item()/count\n",
    "\n",
    "validate(net,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b10483-1eb1-47d1-b1c1-9a5cebc14a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting\n",
    "def train(net,train_loader,test_loader,optimizer=None,lr=0.01,epochs=10,loss_fn=nn.NLLLoss()):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    res = { 'train_loss' : [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for ep in range(epochs):\n",
    "        tl,ta = train_epoch(net,train_loader,optimizer=optimizer,lr=lr,loss_fn=loss_fn)\n",
    "        vl,va = validate(net,test_loader,loss_fn=loss_fn)\n",
    "        print(f\"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}\")\n",
    "        res['train_loss'].append(tl)\n",
    "        res['train_acc'].append(ta)\n",
    "        res['val_loss'].append(vl)\n",
    "        res['val_acc'].append(va)\n",
    "    return res\n",
    "\n",
    "# Re-initialize the network to start from scratch\n",
    "net = nn.Sequential(\n",
    "        nn.Flatten(), \n",
    "        nn.Linear(784,10), # 784 inputs, 10 outputs\n",
    "        nn.LogSoftmax())\n",
    "\n",
    "hist = train(net,train_loader,test_loader,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e06acd-6d48-44b2-a4ea-1b853e4be3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(hist['train_acc'], label='Training acc')\n",
    "plt.plot(hist['val_acc'], label='Validation acc')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(hist['train_loss'], label='Training loss')\n",
    "plt.plot(hist['val_loss'], label='Validation loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96a064-c165-4c0b-98c8-e2bf12da124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tensor = next(net.parameters())\n",
    "fig,ax = plt.subplots(1,10,figsize=(15,4))\n",
    "for i,x in enumerate(weight_tensor):\n",
    "    ax[i].imshow(x.view(28,28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bc1b9-115f-47b3-ab8e-d2a549068cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Flatten(), \n",
    "        nn.Linear(784,100),     # 784 inputs, 100 outputs\n",
    "        nn.ReLU(),              # Activation Function\n",
    "        nn.Linear(100,10),      # 100 inputs, 10 outputs\n",
    "        nn.LogSoftmax(dim=0))\n",
    "\n",
    "summary(net,input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c2b4d-27bf-4fb6-b4a6-901eb7e1cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu, log_softmax\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden = nn.Linear(784,100)\n",
    "        self.out = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.hidden(x)\n",
    "        x = relu(x)\n",
    "        x = self.out(x)\n",
    "        x = log_softmax(x,dim=0)\n",
    "        return x\n",
    "\n",
    "net = MyNet()\n",
    "\n",
    "summary(net,input_size=(1,28,28),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f667d1c-a89d-4f9b-a775-f083916631be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)\n",
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df57bfb-8a64-4085-9c56-117b82535b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
