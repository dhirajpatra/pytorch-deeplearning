{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157b88db-16b9-4c7d-a9d3-59232514c849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff2ad98-e687-4d98-aeef-96865d9804da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x10621b1c0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x106264cd0>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =',z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69ce77f-786d-42e4-8413-50ef28f981f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0927, 0.0086, 0.0453],\n",
      "        [0.0927, 0.0086, 0.0453],\n",
      "        [0.0927, 0.0086, 0.0453],\n",
      "        [0.0927, 0.0086, 0.0453],\n",
      "        [0.0927, 0.0086, 0.0453]])\n",
      "tensor([0.0927, 0.0086, 0.0453])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23b545e-e55f-40a8-922c-accc4b997e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89de3a12-2eb7-43f4-8f35-693ad8bd5623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df896d81-4a0c-418e-ae05-42e4dc15fb29",
   "metadata": {},
   "source": [
    "In a forward pass, autograd does two things simultaneously:\n",
    "\n",
    "runs the requested operation to compute a resulting tensor, and\n",
    "maintains the operation’s gradient function in the DAG.\n",
    "The backward pass kicks off when .backward() is called on the DAG root. autograd then:\n",
    "\n",
    "computes the gradients from each .grad_fn,\n",
    "accumulates them in the respective tensor’s .grad attribute, and\n",
    "using the chain rule, propagates all the way to the leaf tensors.\n",
    "DAGs are dynamic in PyTorch\n",
    "\n",
    "An important thing to note is that the graph is recreated from scratch; after each .backward() call, autograd starts populating a new graph. This is exactly what allows you to use control flow statements in your model; you can change the shape, size and operations at every iteration if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191bca8-9575-4ed4-a4ac-7a10df3d886b",
   "metadata": {},
   "source": [
    "For a vector function  \n",
    "y\n",
    "​\n",
    " =f( \n",
    "x\n",
    " ), where  \n",
    "x\n",
    " =⟨x \n",
    "1\n",
    "​\n",
    " ,…,x \n",
    "n\n",
    "​\n",
    " ⟩ and  \n",
    "y\n",
    "​\n",
    " =⟨y \n",
    "1\n",
    "​\n",
    " ,…,y \n",
    "m\n",
    "​\n",
    " ⟩, a gradient of  \n",
    "y\n",
    "​\n",
    "  with respect to  \n",
    "x\n",
    "  is given by a Jacobian matrix, whose element J \n",
    "ij\n",
    "​\n",
    "  contains  \n",
    "∂x \n",
    "j\n",
    "​\n",
    " \n",
    "∂y \n",
    "i\n",
    "​\n",
    " \n",
    "​\n",
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b1f140-afd0-4c49-8c0a-3a1a9ef746a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb6e15-a071-4d1d-8a1b-f4936cfe9854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
